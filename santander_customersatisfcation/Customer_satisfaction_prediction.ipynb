{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Satisfaction Prediction Challenge: IE MBD-O1 Group G\n",
    "\n",
    "Team members: A.Olivier, J.Kim, I.Ruperez, P.Viland, D.Istiartomo, S.Arumugan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Description\n",
    "\n",
    "* Goal: Predicting the probability of how unsatisfied a customer is based on numerous anonymized variabales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing and Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of data\n",
    "print(\"training set has {} observations and {} columns.\".format(train.shape[0],train.shape[1]))\n",
    "print(\"test set has {} observations and {} columns.\".format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data\n",
    "print(\"missing data for training set:\",len(train.isnull().sum()[train.isnull().sum() > 0]))\n",
    "print(\"missing data for test set:\",len(test.isnull().sum()[test.isnull().sum() > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first few rows of training data\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if IDs are unique\n",
    "print(\"check if training IDs are unique:\", len(train.ID.unique()) == len(train))\n",
    "print(\"check if test IDs are unique:\", len(test.ID.unique()) == len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of satisfied vs not satisfied customers\n",
    "# where 1 is unsatisfied customer\n",
    "# and 0 is satisfied customer\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(train.TARGET)\n",
    "plt.title(\"Satisfied vs not-satisfied customer\")\n",
    "plt.show()\n",
    "\n",
    "train.TARGET.value_counts() / len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is highly imbalanced, with more than 96% of the customers recording as 'satisfied', while merely a little less than 4% saying they are not. This means that we need to be careful when predicting class, as class 0 may dominate the prediction. We will be using stratified corss validation to ensure that this isn't the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for columns with a single unique value\n",
    "# remove these columns because they add no value to the training set\n",
    "cols_single = [i for i in train.columns if len(np.unique(train[i])) == 1]\n",
    "train = train.drop(cols_single, axis = 1)\n",
    "\n",
    "# also remove from test\n",
    "test = test.drop(cols_single, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix to see relationship among variables\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.matshow(train.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation with target variable\n",
    "from scipy.stats import pearsonr\n",
    "corr_df = pd.DataFrame()\n",
    "for i,v in enumerate(train.columns):\n",
    "    corr_df.loc[i,'col'] = v\n",
    "    corr_df.loc[i,'corr_score'] = pearsonr(train.TARGET, train[v])[0]\n",
    "    \n",
    "corr_df.sort_values('corr_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient seems low, but that may be because the relationship may not be strictly linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the columns can be identified with different names in the front\n",
    "# let's check that 3 alphabet code\n",
    "col_code = np.unique([i[:3] for i in train.columns if i not in ['TARGET', 'ID']])\n",
    "col_code\n",
    "\n",
    "# count the number of unique values\n",
    "for i in col_code:\n",
    "    print('----------'+i+'----------')\n",
    "    unique = []\n",
    "    count = 0\n",
    "    for j in train.columns:\n",
    "        if j[:3] == i:\n",
    "            unique.append(len(np.unique(train[j])))\n",
    "            count = count + 1\n",
    "    print(np.unique(unique))\n",
    "    print('total number of columns:', count)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to see that columns with 'ind' are binary (only 2 unique values). Columns with 'num' are discrete values (values are integers, possibly multi labels categorical variable). 'sal' is actually short for 'saldo', which means balance in Spanish. 'del' is short for 'delta', which may mean hedge ratio. Note that there are negative values for these columns. 'var' and 'imp' are other float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicate columns\n",
    "# meaning columns with exact same values\n",
    "from itertools import combinations\n",
    "cols = train.columns.tolist()\n",
    "cols.remove('ID')\n",
    "cols.remove('TARGET')\n",
    "\n",
    "\n",
    "col_combinations = list(combinations(cols,2))\n",
    "same_col_vals = []\n",
    "\n",
    "for i in col_combinations:\n",
    "    if (train[i[0]] == train[i[1]]).all():\n",
    "        same_col_vals.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that all the columns in the same_col_vals are unique\n",
    "# compare length to do that\n",
    "u = []\n",
    "for i in same_col_vals:\n",
    "    u.append(i[0])\n",
    "    u.append(i[1])\n",
    "print((len(same_col_vals) * 2) == len(u))\n",
    "\n",
    "# remove one of the column pairs with same \n",
    "cols_to_remove = [i[0] for i in same_col_vals]\n",
    "train = train.drop(cols_to_remove, axis = 1)\n",
    "test = test.drop(cols_to_remove, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current shape of dataset\n",
    "print(\"training set has {} observations and {} columns after cleaning.\".format(train.shape[0],train.shape[1]))\n",
    "print(\"test set has {} observations and {} columns after cleaning.\".format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "63 columns were deleted from both the training and test set because they added no value to the dataset, either because they only had a single value for all rows, or because they are duplicate columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initial Model Training\n",
    "\n",
    "Since there are still 300+ columns and all are anonymized, there isn't much room for feature engineering at this stage. Therefore, we will first create some baseline classification model.\n",
    "\n",
    "The score metric for this challenge is AUC area, and the actual submission value for the challenge is the probability of belonging to class 1 (Unsatisfied customers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import pipeline and other preprocessing/evaluation tools\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide features (x) and target (y)\n",
    "# store ID separately\n",
    "y = train.TARGET\n",
    "train_id = train.ID\n",
    "train_x = train.drop(['TARGET','ID'], axis = 1)\n",
    "\n",
    "# define stratifiedkfold fdor cross validation\n",
    "# with random state 42\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build pipeline for baseline random forest classification model\n",
    "pipeline_baseline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "scores_baseline = cross_val_score(pipeline_baseline, train_x, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_baseline.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build pipeline for baseline XGBoost classification model\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', XGBClassifier())\n",
    "]) \n",
    "\n",
    "scores_baseline = cross_val_score(pipeline_xgb, train_x, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_baseline.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline XGBoost model's cross validation score is decent, but we can probably do better through more feature engineering and hyperparameter tuning.\n",
    "\n",
    "Since there are still 300+ columns, there is a high possibility that there are columns that are highly correlated and are adding noise to the model rather than value. Let's try to reduce the number of features used for training process by:\n",
    "- PCA: feature extraction\n",
    "- Feature reduction based on feature importance calculated by an ensemble tree model (XGBoost and Adaboost in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA: feature extraction\n",
    "# selecting bset n_components by \n",
    "# comparing variance of different n\n",
    "scaled_x = StandardScaler().fit_transform(train_x)\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(scaled_x)\n",
    "\n",
    "plt.figure(1, figsize = (8,6))\n",
    "plt.clf()\n",
    "plt.axes([.2,.2,.7,.7])\n",
    "plt.plot(pca.explained_variance_[:200], linewidth = 2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that components seem to give little or almost no added value when explaning the variance of the dataset at around 150. We can make a cumulative explained variance graph to figure out the best n_components number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try cumulative explained variance with different pca n values\n",
    "for i in [100,120,140,160]:\n",
    "    pca = PCA(n_components = i)\n",
    "    pca.fit(scaled_x)\n",
    "    cum_explained_var = []\n",
    "    for i in range(0, len(pca.explained_variance_ratio_)):\n",
    "        if i == 0:\n",
    "            cum_explained_var.append(pca.explained_variance_ratio_[i])\n",
    "        else:\n",
    "            cum_explained_var.append(pca.explained_variance_ratio_[i] + \n",
    "                                     cum_explained_var[i-1])\n",
    "    plt.plot(range(len(pca.explained_variance_ratio_)),cum_explained_var, linewidth = 2)\n",
    "    plt.title(\"n = {}: total explained variance {}\".format(i, max(cum_explained_var)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8312393833093451, total= 1.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8148105593326542, total= 1.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  9.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8322466180166463, total= 1.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 11.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8416643876663689, total= 1.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 12.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8292144911655939, total= 1.6min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 14.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.811150527325024, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 15.9min finished\n"
     ]
    }
   ],
   "source": [
    "# use 160 as pca number and build pipeline for xgb\n",
    "pipeline_pca_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components = 160)),\n",
    "    ('clf', XGBClassifier())\n",
    "])\n",
    "\n",
    "scores_pca_xgb = cross_val_score(pipeline_pca_xgb, train_x, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.822802418642088"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_pca_xgb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores don't seem to improve much. Let's try tuning the hyperparameters, to see if there are any improvements in the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter tuning I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost parameter tuning 1\n",
    "# tuning max depth and min child weight\n",
    "xgb_hp_1 = XGBClassifier(seed=42)\n",
    "\n",
    "xgb_param_1 = {\n",
    " 'clf__max_depth':range(3,10,2),\n",
    " 'clf__min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "pipeline_xgb_hp_1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_hp_1)\n",
    "])\n",
    "\n",
    "xgb_rand_1 = RandomizedSearchCV(pipeline_xgb_hp_1, param_distributions = xgb_param_1,\n",
    "                             cv = 5, scoring = 'roc_auc', verbose = 5)\n",
    "\n",
    "xgb_rand_1.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the best parameters based on the randomizedsearchCV\n",
    "xgb_hp_2 = xgb_rand_1.best_estimator_\n",
    "xgb_hp_2.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the best estimator from above to tune gamma this time\n",
    "xgb_hp_2 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1,learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=5, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
    "       subsample=1)\n",
    "\n",
    "xgb_param_2 = {\n",
    " 'clf__gamma':[i/10.0 for i in range(0,5)]}\n",
    "\n",
    "pipeline_xgb_hp_2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_hp_2)\n",
    "])\n",
    "\n",
    "xgb_grid_2 = GridSearchCV(pipeline_xgb_hp_2, param_grid = xgb_param_2,\n",
    "                             cv = 5, scoring = 'roc_auc', verbose = 5)\n",
    "\n",
    "xgb_grid_2.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the best estimator from above \n",
    "# to tune subsample and colsample_bytree this time\n",
    "xgb_hp_3 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       learning_rate=0.1, max_delta_step=0,max_depth=3, min_child_weight=5,missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True, gamma = 0.4)\n",
    "\n",
    "xgb_param_3 = {\n",
    "    'clf__subsample': [i/10.0 for i in range(6,10)],\n",
    "    'clf__colsample_bytree': [i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "pipeline_xgb_hp_3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_hp_3)\n",
    "])\n",
    "\n",
    "xgb_rand_3 = RandomizedSearchCV(pipeline_xgb_hp_3, param_distributions = xgb_param_3,\n",
    "                             cv = 5, scoring = 'roc_auc', verbose = 5)\n",
    "\n",
    "xgb_rand_3.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the best estimator from above \n",
    "# to tune reg_alpha this time\n",
    "xgb_hp_4 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       learning_rate=0.1, max_delta_step=0,max_depth=3, min_child_weight=5,missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True, gamma = 0.4,\n",
    "        colsample_bytree= 0.6, subsample= 0.8)\n",
    "\n",
    "xgb_param_4 = {\n",
    "    'clf__reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "pipeline_xgb_hp_4 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_hp_4)\n",
    "])\n",
    "\n",
    "xgb_grid_4 = GridSearchCV(pipeline_xgb_hp_4, param_grid = xgb_param_4,\n",
    "                             cv = 5, scoring = 'roc_auc', verbose = 5)\n",
    "\n",
    "xgb_grid_4.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best parameters identified for XGboost\n",
    "# and define the best XGboost estimator\n",
    "xgb_hp_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=0.4, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=5, missing=None,\n",
    "       n_estimators=100, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0.001,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
    "       subsample=0.8)\n",
    "\n",
    "scaled_x = StandardScaler().fit_transform(train_x)\n",
    "xgb_hp_best.fit(scaled_x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree models like XGBoost have a feature called \"feature importance\", which meausres how important individual feature is for the model. We can use this feature to 'filter' features that do not add as much value to the classification task by dropping all columns with 0.0 feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dataframe of feature importance for the best xgb model\n",
    "xgb_feature_imp = pd.DataFrame({'feature': train_x.columns.tolist(),\n",
    "             'feature_importance': xgb_hp_best.feature_importances_})\n",
    "\n",
    "# store columns with feature importance = 0\n",
    "cols_del = xgb_feature_imp[xgb_feature_imp.feature_importance == 0.0].feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop colums with 0 importance from the training and test set\n",
    "train_x_2 = train_x.drop(cols_del, axis = 1)\n",
    "test_ID = test.ID\n",
    "test_2 = test.drop(cols_del, axis = 1)\n",
    "test_2 = test_2.drop('ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale x2 and test 2\n",
    "scaler = StandardScaler()\n",
    "train_x_2_scaled = scaler.fit_transform(train_x_2)\n",
    "test_2_scaled = scaler.transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# re-train the xgboost model with predefine parameters\n",
    "# using the new dataset\n",
    "xgb_hp_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=0.4, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=5, missing=None,\n",
    "       n_estimators=100, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0.001,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
    "       subsample=0.8)\n",
    "\n",
    "pipeline_xgb_x2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_hp_best)\n",
    "]) \n",
    "\n",
    "scores_xgb_x2 = cross_val_score(pipeline_xgb_x2, train_x_2, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter Tuning II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the process above for XGBoost with Adaboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adaboost classifier\n",
    "ada_x2 = AdaBoostClassifier(random_state = 42)\n",
    "\n",
    "pipeline_ada_x2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', ada_x2)\n",
    "]) \n",
    "\n",
    "scores_ada_x2 = cross_val_score(pipeline_ada_x2, train_x_2, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adaboost classifier\n",
    "# get the best estimator from above\n",
    "ada_hp_1 = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, random_state=42)\n",
    "\n",
    "ada_param_1 = {\n",
    "    'clf__n_estimators': [50, 100, 500, 1000],\n",
    "    'clf__learning_rate': [1.0, 0.1, 0.05]\n",
    "}\n",
    "\n",
    "pipeline_ada_hp_1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', ada_hp_1)\n",
    "])\n",
    "\n",
    "ada_grid_1 = GridSearchCV(pipeline_ada_hp_1, param_grid = ada_param_1,\n",
    "                             cv = 5, scoring = 'roc_auc', verbose = 5)\n",
    "\n",
    "ada_grid_1.fit(train_x2,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define adaboost estimator with best parameters\n",
    "ada_grid_1.best_estimator_\n",
    "ada_hp_best = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=0.05, n_estimators=500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feature Engineering III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try and reduce further columns by also filtering features based on importance of adaboost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance of adaboosts\n",
    "ada_imp = pd.DataFrame({'features': train_x_2.columns.tolist(),'feat_imp': ada_hp_best.feature_importances_})\n",
    "cols_drop_2 = ada_imp[ada_imp.feat_imp == 0.0].features.tolist()\n",
    "\n",
    "# drop features from training and test set\n",
    "train_x_3 = train_x_2.drop(cols_drop_2, axis = 1)\n",
    "test_3 = test_2.drop(cols_drop_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale x3 and test 3\n",
    "scaler = StandardScaler()\n",
    "train_x_3_scaled = scaler.fit_transform(train_x_3)\n",
    "test_3_scaled = scaler.transform(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgb with new features\n",
    "xgb_hp_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.6, gamma=0.4, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=5, missing=None,\n",
    "       n_estimators=100, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0.001,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
    "       subsample=0.8)\n",
    "\n",
    "pipeline_xgb_x3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', xgb_hp_best)\n",
    "]) \n",
    "\n",
    "scores_xgb_x3 = cross_val_score(pipeline_xgb_x3, train_x_3, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adaboost classifier\n",
    "ada_hp_best = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=0.05, n_estimators=500, random_state=42)\n",
    "\n",
    "pipeline_ada_x3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', ada_hp_best)\n",
    "])\n",
    "\n",
    "scores_ada_x3 = cross_val_score(pipeline_ada_x3, train_x_3, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Hyperparameter Tuning III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try one more parameter tuning for gradientboosting classifier, using the new features set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gradient boost model\n",
    "gbm = GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "pipeline_gbm_x3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', gbm)\n",
    "])\n",
    "\n",
    "scores_gbm_x3 = cross_val_score(pipeline_gbm_x3, train_x_3, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gbm tuning\n",
    "gbm_hp_1 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gbm_param_1 = {\n",
    "    'clf__max_depth': range(5,16,2),\n",
    "    'clf__min_samples_split': range(200,1001,200)\n",
    "}\n",
    "\n",
    "pipeline_gbm_hp_1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', gbm_hp_1)\n",
    "])\n",
    "\n",
    "gbm_rand_1 = RandomizedSearchCV(pipeline_gbm_hp_1, param_distributions = gbm_param_1,\n",
    "                             cv = 5, scoring = 'roc_auc', verbose = 5)\n",
    "\n",
    "gbm_rand_1.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best gbm with new features\n",
    "gbm_hp_best = GradientBoostingClassifier(min_samples_split= 1000,\n",
    "                            max_depth= 5,\n",
    "                           random_state = 42)\n",
    "\n",
    "pipeline_gbm_x3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', gbm_hp_best)\n",
    "]) \n",
    "\n",
    "scores_gbm_hp_x3 = cross_val_score(pipeline_gbm_x3, train_x_3, y,\n",
    "                                 cv = skf, scoring = 'roc_auc', verbose = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While all xgboost, adaboost, and gbm are ensemble models of their own (tree ensembles), we can create another ensemble using the defined models above. Ensemble models are more robust (since the prediction is based on multiple models), and thus are less vulnerable to variance errors. We will use the votingclassifier function to create different ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators_2 = [('xgb', xgb_hp_best),('ada', ada_hp_best)]\n",
    "\n",
    "#Voting Classifier\n",
    "vc_2 = VotingClassifier(estimators= estimators_2,\n",
    "                          voting='soft',            #soft for probability\n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None\n",
    "                          )\n",
    "\n",
    "#Voting Classifier fit\n",
    "vc_2 = vc_2.fit(train_x_3_scaled, y)\n",
    "\n",
    "#Voting Classifier predict\n",
    "VC_pred_2 = vc_2.predict_proba(test_3_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators_3 = [('xgb', xgb_hp_best),('ada', ada_hp_best), ('gbm', gbm_hp_best)]\n",
    "\n",
    "#Voting Classifier\n",
    "vc_3 = VotingClassifier(estimators= estimators_3,\n",
    "                          voting='soft',            #soft for probability\n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None\n",
    "                          )\n",
    "\n",
    "#Voting Classifier fit\n",
    "vc_3 = vc_3.fit(train_x_3_scaled, y)\n",
    "\n",
    "#Voting Classifier predict\n",
    "VC_pred_3 = vc_3.predict_proba(test_3_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators_4 = [('xgb', xgb_hp_best),('gbm', gbm_hp_best)]\n",
    "\n",
    "#Voting Classifier\n",
    "vc_4 = VotingClassifier(estimators= estimators_4,\n",
    "                          voting='soft',            #soft for probability\n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None\n",
    "                          )\n",
    "\n",
    "#Voting Classifier fit\n",
    "vc_4 = vc_3.fit(train_x_3_scaled, y)\n",
    "\n",
    "#Voting Classifier predict\n",
    "VC_pred_4 = vc_4.predict_proba(test_3_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators_5 = [('xgb', xgb_hp_best),('gbm', gbm_hp_best)]\n",
    "\n",
    "#Voting Classifier\n",
    "vc_5 = VotingClassifier(estimators= estimators_5,\n",
    "                          voting='soft',            #soft for probability\n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None\n",
    "                          )\n",
    "\n",
    "#Voting Classifier fit\n",
    "vc_5 = vc_5.fit(train_x_2_scaled, y)\n",
    "\n",
    "#Voting Classifier predict\n",
    "VC_pred_5 = vc_5.predict_proba(test_2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators_6 = [('xgb', xgb_hp_best),('ada', ada_hp_best), ('gbm', gbm_hp_best)]\n",
    "\n",
    "#Voting Classifier\n",
    "vc_6 = VotingClassifier(estimators= estimators_6,\n",
    "                          voting='soft',            #soft for probability\n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None\n",
    "                          )\n",
    "\n",
    "#Voting Classifier fit\n",
    "vc_6 = vc_6.fit(train_x_2_scaled, y)\n",
    "\n",
    "#Voting Classifier predict\n",
    "VC_pred_6 = vc_6.predict_proba(test_2_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Predictions & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge had 2 different types of score systems: a private, and a public one. Our results had different scores for the best private score and the best public score, so here we display both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best private score model: \n",
    "# XGBoost model using 68 variables (training set 2)\n",
    "# private score: 0.824089\n",
    "# public score: 0.836971\n",
    "pipeline_xgb_x2.fit(train_x_2, y)\n",
    "predictions = pipeline_xgb_x2.predict_proba(test_2)\n",
    "\n",
    "submission_xgb = pd.DataFrame({'ID': test_ID, 'TARGET': [i[1] for i in predictions]})\n",
    "submission_xgb.to_csv(\"submission_xgb_20180620_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best public score model: \n",
    "# Ensembled model using XGboost and GBM\n",
    "# with 68 variables (training set 2)\n",
    "# private score: 0.824038\n",
    "# public score: 0.837158\n",
    "vc_5.fit(train_x_2, y)\n",
    "VC_pred_5 = vc_5.predict_proba(test_2)\n",
    "\n",
    "submission_vc = pd.DataFrame({'ID': test_ID, 'TARGET': [i[1] for i in VC_pred_5]})\n",
    "submission_xgb.to_csv(\"submission_vc5_20180622_10.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
